{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Estimated time for this notebook: 15 minutes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use testing frameworks?\n",
    "\n",
    "Frameworks should simplify our lives:\n",
    "\n",
    "* Should be easy to add simple test\n",
    "* Should be possible to create complex test:\n",
    "    * Fixtures\n",
    "    * Setup/Tear down\n",
    "    * Parameterized tests (same test, mostly same input)\n",
    "* Find all our tests in a complicated code-base \n",
    "* Run all our tests with a quick command\n",
    "* Run only some tests, e.g. ``test --only \"tests about fields\"``\n",
    "* **Report failing tests**\n",
    "* Additional goodies, such as code coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Language agnostic: [CTest](https://cmake.org/cmake/help/latest/manual/ctest.1.html)\n",
    "  * Test runner for executables, bash scripts, etc...\n",
    "  * Great for legacy code hardening\n",
    "    \n",
    "* C unit-tests:\n",
    "    * all c++ frameworks,\n",
    "    * [Check](https://libcheck.github.io/check/),\n",
    "    * [CUnit](http://cunit.sourceforge.net)\n",
    "\n",
    "* C++ unit-tests:\n",
    "    * [CppTest](http://cpptest.sourceforge.net/),\n",
    "    * [Boost::Test](https://www.boost.org/doc/libs/1_79_0/libs/test/doc/html/index.html),\n",
    "    * [google-test](https://google.github.io/googletest/),\n",
    "    * [Catch](https://github.com/catchorg/Catch2)\n",
    "\n",
    "* Python unit-tests:\n",
    "    * [unittest](https://docs.python.org/3/library/unittest.html) comes with standard python library\n",
    "    * [pytest](http://pytest.org/latest/), includes test discovery, coverage, etc\n",
    "\n",
    "* R unit-tests:\n",
    "    * [RUnit](https://cran.r-project.org/web/packages/RUnit/index.html),\n",
    "    * [testthat](https://testthat.r-lib.org/)\n",
    "\n",
    "* Fortran unit-tests:\n",
    "    * [pfunit](https://github.com/Goddard-Fortran-Ecosystem/pFUnit)(works with MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytest framework: usage\n",
    "\n",
    "[pytest](https://docs.pytest.org/en/latest/) is a recommended python testing framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use its tools in the notebook for on-the-fly tests in the notebook. This, happily, includes the negative-tests example we were looking for a moment ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_only_accept_positive_numbers(number):\n",
    "    # Check input\n",
    "    if number < 0:\n",
    "        raise ValueError(\"Input \" + str(number) + \" is negative\")\n",
    "\n",
    "    # Do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import raises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with raises(ValueError):\n",
    "    I_only_accept_positive_numbers(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but the real power comes when we write a test file alongside our code files in our homemade packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#on windows replace '%%bash' with %%cmd\n",
    "rm -rf saskatchewan\n",
    "mkdir -p saskatchewan\n",
    "touch saskatchewan/__init__.py #on windows replace with 'type nul > saskatchewan/__init__.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing saskatchewan/overlap.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile saskatchewan/overlap.py\n",
    "def overlap(field1, field2):\n",
    "    left1, bottom1, top1, right1 = field1\n",
    "    left2, bottom2, top2, right2 = field2\n",
    "\n",
    "    overlap_left = max(left1, left2)\n",
    "    overlap_bottom = max(bottom1, bottom2)\n",
    "    overlap_right = min(right1, right2)\n",
    "    overlap_top = min(top1, top2)\n",
    "    # Here's our wrong code again\n",
    "    overlap_height = overlap_top - overlap_bottom\n",
    "    overlap_width = overlap_right - overlap_left\n",
    "\n",
    "    return overlap_height * overlap_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing saskatchewan/test_overlap.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile saskatchewan/test_overlap.py\n",
    "from .overlap import overlap\n",
    "\n",
    "\n",
    "def test_full_overlap():\n",
    "    assert overlap((1.0, 1.0, 4.0, 4.0), (2.0, 2.0, 3.0, 3.0)) == 1.0\n",
    "\n",
    "\n",
    "def test_partial_overlap():\n",
    "    assert overlap((1, 1, 4, 4), (2, 2, 3, 4.5)) == 2.0\n",
    "\n",
    "\n",
    "def test_no_overlap():\n",
    "    assert overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5)) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform linux -- Python 3.8.15, pytest-7.2.0, pluggy-1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rootdir: /home/runner/work/rse-course/rse-course/module05_testing_your_code/saskatchewan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plugins: anyio-3.6.2, pylama-8.4.1, cov-4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 3 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_overlap.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                      [100%]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================== FAILURES ===================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1m_______________________________ test_no_overlap ________________________________\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_no_overlap\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">       \u001b[94massert\u001b[39;49;00m overlap((\u001b[94m1\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m), (\u001b[94m4.5\u001b[39;49;00m, \u001b[94m4.5\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) == \u001b[94m0.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mE       assert 0.25 == 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mE        +  where 0.25 = overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mtest_overlap.py\u001b[0m:13: AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFAILED\u001b[0m test_overlap.py::\u001b[1mtest_no_overlap\u001b[0m - assert 0.25 == 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +  where 0.25 = overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.18s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests failed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#%%cmd #(windows)\n",
    "cd saskatchewan\n",
    "pytest || echo \"Tests failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it reported **which** test had failed, how many tests ran, and how many failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symbol `..F` means there were three tests, of which the third one failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest will:\n",
    "\n",
    "* automagically finds files ``test_*.py``\n",
    "* collects all subroutines called ``test_*``\n",
    "* runs tests and reports results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some options:\n",
    "\n",
    "* help: `pytest --help`\n",
    "* run only tests for a given feature: `pytest -k foo` # tests with 'foo' in the test name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage reports\n",
    "\n",
    "Using `pytest` it is possisble to see, which lines of code have or haven't been execuded by you tests.\n",
    "\n",
    "The command below will produce a html files which highlights the coverage of your tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform linux -- Python 3.8.15, pytest-7.2.0, pluggy-1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rootdir: /home/runner/work/rse-course/rse-course/module05_testing_your_code/saskatchewan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plugins: anyio-3.6.2, pylama-8.4.1, cov-4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 3 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_overlap.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                      [100%]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================== FAILURES ===================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1m_______________________________ test_no_overlap ________________________________\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_no_overlap\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">       \u001b[94massert\u001b[39;49;00m overlap((\u001b[94m1\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m), (\u001b[94m4.5\u001b[39;49;00m, \u001b[94m4.5\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) == \u001b[94m0.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mE       assert 0.25 == 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mE        +  where 0.25 = overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mtest_overlap.py\u001b[0m:13: AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- coverage: platform linux, python 3.8.15-final-0 -----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage HTML written to dir htmlcov\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFAILED\u001b[0m test_overlap.py::\u001b[1mtest_no_overlap\u001b[0m - assert 0.25 == 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +  where 0.25 = overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.17s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests failed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#%%cmd #(windows)\n",
    "cd saskatchewan\n",
    "pytest --cov=. --cov-report=html || echo \"Tests failed\"\n",
    "# MacOS:\n",
    "#Â open htmlcov/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with floating points\n",
    "\n",
    "## Floating points are not reals\n",
    "\n",
    "\n",
    "Floating points are inaccurate representations of real numbers:\n",
    "\n",
    "`1.0 == 0.99999999999999999` is true to the last bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can lead to numerical errors during calculations: $1000 (a - b) \\neq 1000a - 1000b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2737367544323206e-13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * 1.0 - 1000.0 * 0.9999999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * (1.0 - 0.9999999999999998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Both* results are wrong: `2e-13` is the correct answer.\n",
    "\n",
    "The size of the error will depend on the magnitude of the floating points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4901161193847656e-08"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * 1e5 - 1000.0 * 0.9999999999999998e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be `2e-8`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing floating points\n",
    "\n",
    "Use the \"approx\", for a default of a relative tolerance of $10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from pytest import approx\n",
    "\n",
    "assert 0.7 == approx(0.7 + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or be more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "magnitude = 0.7\n",
    "assert 0.7 == approx(0.701, rel=0.1, abs=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing tolerances is a big area of debate: https://software-carpentry.org/blog/2014/10/why-we-dont-teach-testing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing vectors of floating points\n",
    "\n",
    "Numerical vectors are best represented using [numpy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array, pi\n",
    "\n",
    "vector_of_reals = array([0.1, 0.2, 0.3, 0.4]) * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy ships with a number of assertions (in `numpy.testing`) to make\n",
    "comparison easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array, pi\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "expected = array([0.1, 0.2, 0.3, 0.4, 1e-12]) * pi\n",
    "actual = array([0.1, 0.2, 0.3, 0.4, 2e-12]) * pi\n",
    "actual[:-1] += 1e-6\n",
    "assert_allclose(actual, expected, rtol=1e-5, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It compares the difference between `actual` and `expected` to ``atol + rtol * abs(expected)``."
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "display_name": "Test Frameworks"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "44f733b714c696d9811e1e4790628c0e5019891ced3dbb8112bc5b951948cffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}